<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>多为垃圾文</title>
  <subtitle>无聊之记</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://blog.livexia.site/"/>
  <updated>2017-04-10T03:56:23.000Z</updated>
  <id>http://blog.livexia.site/</id>
  
  <author>
    <name>livexia</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Seasons In The Sun</title>
    <link href="http://blog.livexia.site/2017/04/10/music_4/"/>
    <id>http://blog.livexia.site/2017/04/10/music_4/</id>
    <published>2017-04-10T03:46:30.000Z</published>
    <updated>2017-04-10T03:56:23.000Z</updated>
    
    <content type="html"><![CDATA[<hr>
<ul>
<li>演唱：Westlife、Nirvana</li>
<li>歌手：Black Box Recorder</li>
<li>专辑：The Worst Of Black Box Recorder</li>
<li>语种：欧美</li>
<li>曲风：慢摇<a id="more"></a></li>
</ul>
<hr>
<iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="86" src="//music.163.com/outchain/player?type=2&id=3950239&auto=1&height=66"></iframe>

<iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="86" src="//music.163.com/outchain/player?type=2&id=29775439&auto=0&height=66"></iframe>

<iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="86" src="//music.163.com/outchain/player?type=2&id=20707571&auto=0&height=66"></iframe>

<h2 id="Seasons-In-The-Sun"><a href="#Seasons-In-The-Sun" class="headerlink" title="Seasons In The Sun"></a>Seasons In The Sun</h2><p><strong>注：歌词来自Black Box Recorder版本</strong><br>Goodbye to you, my trusted friend.<br>再见了 我的挚友<br>We’ve known each other since we were nine or ten.<br>我们从十岁左右就认识了<br>Together we’ve climbed hills and trees,<br>我们一起爬山爬树<br>learned of love and ABC’s,<br>一起学习爱与字母<br>skinned our hearts and skinned our knees.<br>共同经历成长的伤痛<br>Goodbye, my friend.<br>再见了 我的朋友<br>It’s hard to die<br>离开你真的很难<br>when all the birds are singing in the sky.<br>当所有的鸟儿都在天空尽情歌唱<br>Now that spring is in the air<br>所有的花儿都盛开烂漫<br>pretty boys are everywhere.<br>美丽的女孩儿随处可见<br>Think of me and I’ll be there.<br>想想我 我就要去那里了<br>Goodbye, Papa, please pray for me.<br>再见了 爸爸 请为我祈祷吧<br>I was the black sheep of the family.<br>我像是家中的害群之马一般<br>You tried to teach me right from wrong.<br>你试着教我分清是非<br>Too much wine and too much song.<br>我却沉迷于酒乐<br>Wonder how I got along.<br>真不知我是如何过来的<br>Goodbye, papa.<br>再见了 爸爸<br>It’s hard to die when all the birds are singing in the sky.<br>当所有的鸟儿都在天空尽情歌唱 离开你真的很难<br>Now that the spring is in the air,<br>闻到了初春的气息<br>Little children everywhere.<br>到处都会是孩子的身影<br>When you see them, I’ll be there.<br>当你看着他们 我就会在那里</p>
<p>Goodbye, Michelle, my precious one.<br>再见了 Michelle 我的小宝贝<br>You gave me love and helped me find the sun.<br>你给予了我爱和阳光<br>And every time that I was down,<br>每当我沮丧的时候<br>you would always come around,<br>你总是陪在我身边<br>and get my feet back on the ground.<br>让我重拾信心<br>Goodbye, Michelle.<br>再见了 Michelle<br>It’s hard to die when all the birds are singing in the sky<br>当所有的鸟儿都在天空尽情歌唱 离开你真的很难<br>Now that spring is in the air,<br>闻到了初春的气息<br>with the flowers everywhere,<br>所有的花儿都盛开烂漫<br>I wish that we could both be there.<br>我希望我们能一起享受春光<br>We had joy, we had fun,<br>我们曾有过欢声笑语<br>we had seasons in the sun,<br>我们曾一起度过阳光四季<br>but the hills that we climbed were just seasons out of time.<br>但我们一起爬山的美好时光 都已一去不返<br>We had joy, we had fun,we had seasons in the sun,<br>我们曾有过欢声笑语 我们曾一起度过阳光四季<br>but the stars we could reach were just starfish on the beach.<br>但我们所接触的星辰 根本就微不足道</p>
<hr>
<h2 id="链接"><a href="#链接" class="headerlink" title="链接"></a>链接</h2><p><a href="http://music.163.com/#/song?id=437250607" target="_blank" rel="external">网易云</a></p>
]]></content>
    
    <summary type="html">
    
      这三个不同的Seasons In The Sun，虽然表达了完全不一样的意境，但是却可以深深打动我
    
    </summary>
    
      <category term="Music" scheme="http://blog.livexia.site/categories/Music/"/>
    
    
      <category term="music" scheme="http://blog.livexia.site/tags/music/"/>
    
  </entry>
  
  <entry>
    <title>The fourth week|第四周</title>
    <link href="http://blog.livexia.site/2017/04/09/post_5/"/>
    <id>http://blog.livexia.site/2017/04/09/post_5/</id>
    <published>2017-04-09T11:02:59.000Z</published>
    <updated>2017-04-09T11:06:50.000Z</updated>
    
    <content type="html"><![CDATA[<p>TODO:加入其他反反爬虫功能，尝试编写针对网易云的爬虫</p>
<p>由于豆瓣top250没有什么反爬虫，于是我决定对网易云音乐下手，本周先对给定歌单进行获取，得到歌单的基本信息。</p>
<p>新建scrapy项目netease_music, </p>
<p>增加spider，name = getlist</p>
<p>尝试老方法对页面进行爬取书发现返回为js代码段。</p>
<p>由于网易云将所有实质内容存放在iframe标签呢，利用request方法无法取得页面内容。</p>
<p>在网上也看到有人利用selenium先得到iframe标签内内的html代码，再用xpath，对其进行获取。</p>
<p>我略微搜索发现selenium本身测试平台，拿来跑爬虫效率太低，便决定寻求其他方法。</p>
<p>之后在知乎上发现有网易云的api，github：metowolf/NeteaseCloudMusicApi，metowolf/Meting</p>
<p>采取使用网易云音乐的api方式来获取歌单信息。<br>利用api可以简单获取到含有歌单所有信息的json文件，不需要scrapy进行爬取。</p>
<p>利用api也可以抓取评论，找到API简直省力几万倍</p>
<p>总结：本周大部分时间都花在如何解析iframe中，先有抓取方案过于臃肿浪费，找到网易云音乐api省事不少，具体实现本周尚未写好，由于api直接可以导出json，因此这周大部分针对抓取单一歌单的信息的努力直接实现。对于抓取到的.json文件，也可以通过python解析，获取需要的数据。</p>
<p>TODO：解析通过api获得的json文件，留取需要的数据，存入数据库中。模拟登陆网易云，爬取个人的所有歌单，利用网易云音乐api，获得json文件，将其存储在mongdb中。</p>
]]></content>
    
    <summary type="html">
    
      本周针对网易云音乐抓取歌单，结果找到api，直接可以获取歌单信息
    
    </summary>
    
      <category term="创新实践" scheme="http://blog.livexia.site/categories/%E5%88%9B%E6%96%B0%E5%AE%9E%E8%B7%B5/"/>
    
    
      <category term="python" scheme="http://blog.livexia.site/tags/python/"/>
    
      <category term="scrapy" scheme="http://blog.livexia.site/tags/scrapy/"/>
    
  </entry>
  
  <entry>
    <title>个人随想</title>
    <link href="http://blog.livexia.site/2017/04/08/caprice/"/>
    <id>http://blog.livexia.site/2017/04/08/caprice/</id>
    <published>2017-04-08T15:58:35.000Z</published>
    <updated>2017-04-08T16:33:13.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote class="blockquote-center"><p>2017-04-08 23:58:38+08:00<br><strong>突然看到小说里面，陆总是被打成6，之前以为是巧用，今晚却突然想到有可能是，由于口音问题陆6不分。。。</strong></p>
</blockquote>
]]></content>
    
    <summary type="html">
    
      个人随想，可能不甚正确
    
    </summary>
    
      <category term="个人" scheme="http://blog.livexia.site/categories/%E4%B8%AA%E4%BA%BA/"/>
    
      <category term="随想" scheme="http://blog.livexia.site/categories/%E4%B8%AA%E4%BA%BA/%E9%9A%8F%E6%83%B3/"/>
    
    
      <category term="talk" scheme="http://blog.livexia.site/tags/talk/"/>
    
      <category term="随想" scheme="http://blog.livexia.site/tags/%E9%9A%8F%E6%83%B3/"/>
    
  </entry>
  
  <entry>
    <title>推荐过的歌曲</title>
    <link href="http://blog.livexia.site/2017/04/05/music_list/"/>
    <id>http://blog.livexia.site/2017/04/05/music_list/</id>
    <published>2017-04-05T14:31:22.000Z</published>
    <updated>2017-04-10T03:46:24.000Z</updated>
    
    <content type="html"><![CDATA[<hr>
<a id="more"></a>
<blockquote>
<p>最近更新：2017-04-10 11:46:19+08:00</p>
</blockquote>
<iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="420" height="450" src="//music.163.com/outchain/player?type=0&id=653199851&auto=1&height=430"></iframe>

<p><em>注：部分歌曲由于版权问题，无法在线播放</em></p>
<hr>
<h2 id="链接"><a href="#链接" class="headerlink" title="链接"></a>链接</h2><p><a href="http://music.163.com/#/playlist?id=653199851" target="_blank" rel="external">网易云</a></p>
]]></content>
    
    <summary type="html">
    
      推荐过的网易云歌单，部分歌曲由于版权问题，无法在线播放
    
    </summary>
    
      <category term="Music" scheme="http://blog.livexia.site/categories/Music/"/>
    
    
      <category term="music" scheme="http://blog.livexia.site/tags/music/"/>
    
      <category term="music list" scheme="http://blog.livexia.site/tags/music-list/"/>
    
  </entry>
  
  <entry>
    <title>歌曲推荐：我的一个道姑朋友（Cover：Lon）</title>
    <link href="http://blog.livexia.site/2017/04/05/music_3/"/>
    <id>http://blog.livexia.site/2017/04/05/music_3/</id>
    <published>2017-04-05T13:23:08.000Z</published>
    <updated>2017-04-05T13:46:32.000Z</updated>
    
    <content type="html"><![CDATA[<hr>
<ul>
<li>演唱：以冬</li>
<li>专辑：我的一个道姑朋友</li>
<li>语种：华语</li>
<li>曲风：流行、古风<a id="more"></a></li>
</ul>
<hr>
<iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="86" src="//music.163.com/outchain/player?type=2&id=437250607&auto=1&height=66"></iframe>

<h2 id="我的一个道姑朋友（Cover：Lon）"><a href="#我的一个道姑朋友（Cover：Lon）" class="headerlink" title="我的一个道姑朋友（Cover：Lon）"></a>我的一个道姑朋友（Cover：Lon）</h2><p>作曲 : 《一番星》<br>作词 : 陆菱纱<br>原唱：LON<br>后期：圣雨轻纱</p>
<p>而你撑伞拥我入怀中，<br>一字一句誓言多慎重。<br>你眼中有柔情千种，<br>如脉脉春风，冰雪也消融。<br>那年长街春意正浓，<br>策马同游，烟雨如梦。<br>檐下躲雨，<br>望进一双，深邃眼瞳，<br>宛如华山夹着细雪的微风。</p>
<p>雨丝微凉，<br>风吹过暗香朦胧。<br>一时心头悸动，似你温柔剑锋，<br>过处翩若惊鸿。</p>
<p>是否情字写来都空洞，<br>一笔一画斟酌着奉送，<br>甘愿卑微换个笑容，<br>或沦为平庸。</p>
<p>而你撑伞拥我入怀中，<br>一字一句誓言多慎重。<br>你眼中有柔情千种，<br>如脉脉春风，冰雪也消融。</p>
<p>后来谁家喜宴重逢，<br>佳人在侧，烛影摇红。</p>
<p>灯火缱绻，<br>映照一双，如画颜容，<br>宛如豆蔻枝头温柔的旧梦。</p>
<p>对面不识，<br>恍然间思绪翻涌。<br>望你白衣如旧，神色几分冰冻，<br>谁知我心惶恐？</p>
<p>也许我应该趁醉装疯，<br>借你怀抱留一抹唇红。<br>再将旧事轻歌慢诵，<br>任旁人惊动。</p>
<p>可我只能假笑扮从容，<br>侧耳听那些情深意重。<br>不去看你熟悉脸孔，<br>只默默饮酒，多无动于衷。</p>
<p>山门外，雪拂过白衣，又在指尖消融；<br>负长剑，试问江湖偌大，该何去何从？<br>今生至此，像个笑话一样，自己都嘲讽，<br>一厢情愿，有始无终。</p>
<p>若你早与他人两心同，<br>何苦惹我错付了情衷。<br>难道看我失魂落魄，<br>你竟然心动？</p>
<p>所幸经年漂浮红尘中，<br>这颗心已是千疮百孔。<br>怎惧你以薄情为刃，<br>添一道裂缝？</p>
<p>又不会痛。</p>
<p>不如将往事埋在风中，<br>以长剑为碑，以霜雪为冢。<br>此生若是错在相逢，<br>求一个善终。</p>
<p>孤身打马南屏旧桥边过，<br>恰逢山雨来时雾蒙蒙。<br>想起那年伞下轻拥，<br>就像躺在桥索之上，做了一场梦，<br>梦醒后跌落，粉身碎骨，无影亦无踪。</p>
<hr>
<h2 id="链接"><a href="#链接" class="headerlink" title="链接"></a>链接</h2><p><a href="http://music.163.com/#/song?id=437250607" target="_blank" rel="external">网易云</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;演唱：以冬&lt;/li&gt;
&lt;li&gt;专辑：我的一个道姑朋友&lt;/li&gt;
&lt;li&gt;语种：华语&lt;/li&gt;
&lt;li&gt;曲风：流行、古风
    
    </summary>
    
      <category term="Music" scheme="http://blog.livexia.site/categories/Music/"/>
    
    
      <category term="music" scheme="http://blog.livexia.site/tags/music/"/>
    
  </entry>
  
  <entry>
    <title>歌曲推荐：遥远的歌</title>
    <link href="http://blog.livexia.site/2017/04/04/music_2/"/>
    <id>http://blog.livexia.site/2017/04/04/music_2/</id>
    <published>2017-04-04T14:17:27.000Z</published>
    <updated>2017-04-05T13:45:32.000Z</updated>
    
    <content type="html"><![CDATA[<hr>
<ul>
<li>演唱：Cannie</li>
<li>专辑：Bittersweet</li>
<li>语种：华语</li>
<li>曲风：流行<a id="more"></a></li>
</ul>
<hr>
<iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="86" src="//music.163.com/outchain/player?type=2&id=418257688&auto=1&height=66"></iframe>

<h2 id="遥远的歌"><a href="#遥远的歌" class="headerlink" title="遥远的歌"></a>遥远的歌</h2><p>词/曲/编曲/演唱：Cannie Y.</p>
<p>写了一首遥远的歌送给遥远的你</p>
<p>你的笑声我的歌声编织在一起</p>
<p>这是我对旧时光最温暖的回忆</p>
<p>哭着笑着痛着疯着跟过去别离</p>
<p>旧旧的琴弦在吟唱苍白的故事</p>
<p>而你腼腆的笑容是故事的开始</p>
<p>迎面而来的微风像你说话的样子</p>
<p>没有任何预兆这故事戛然而止</p>
<p>人生总有一些些遗憾那就随它去</p>
<p>短暂的阳光也一样温暖了心灵</p>
<p>总有些时光值得怀念却又回不去</p>
<p>回不去的留不下的对你的回忆</p>
<p>人生总有一些些遗憾那就随它去</p>
<p>短暂的阳光也一样温暖了心灵</p>
<p>总有些时光值得怀念却又回不去</p>
<p>回不去的留不下的对你的回忆<br>(Repeat till the end)</p>
<hr>
<h2 id="链接"><a href="#链接" class="headerlink" title="链接"></a>链接</h2><p><a href="http://music.163.com/#/song/418257688" target="_blank" rel="external">网易云</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;演唱：Cannie&lt;/li&gt;
&lt;li&gt;专辑：Bittersweet&lt;/li&gt;
&lt;li&gt;语种：华语&lt;/li&gt;
&lt;li&gt;曲风：流行
    
    </summary>
    
      <category term="Music" scheme="http://blog.livexia.site/categories/Music/"/>
    
    
      <category term="music" scheme="http://blog.livexia.site/tags/music/"/>
    
  </entry>
  
  <entry>
    <title>个人直播地址</title>
    <link href="http://blog.livexia.site/2017/04/04/live_url/"/>
    <id>http://blog.livexia.site/2017/04/04/live_url/</id>
    <published>2017-04-04T13:15:28.000Z</published>
    <updated>2017-04-08T16:24:51.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote class="blockquote-center"><br>经常游戏，日常音乐，偶尔电影。<br><br>steam/origin：livexia<br><a id="more"></a><br>网易云id：livexia<br></blockquote>

<div class="note default"><p><a href="https://live.bilibili.com/52802" target="_blank" rel="external">bilibili:livexia</a> </p>
</div>
<embed height="540" width="96%" quality="high" allowfullscreen="true" type="application/x-shockwave-flash" src="https://static.hdslb.com/live-static/swf/LivePlayerEx_1.swf?room_id=52802&cid=52802&state=LIVE" flashvars="aid=7094514&page=1" pluginspage="//www.adobe.com/shockwave/download/download.cgi?P1_Prod_Version=ShockwaveFlash">

]]></content>
    
    <summary type="html">
    
      我在b站的直播地址，经常游戏什么的。
    
    </summary>
    
      <category term="个人" scheme="http://blog.livexia.site/categories/%E4%B8%AA%E4%BA%BA/"/>
    
    
      <category term="直播" scheme="http://blog.livexia.site/tags/%E7%9B%B4%E6%92%AD/"/>
    
      <category term="视频" scheme="http://blog.livexia.site/tags/%E8%A7%86%E9%A2%91/"/>
    
  </entry>
  
  <entry>
    <title>歌曲推荐：其实，我就在你方圆几里</title>
    <link href="http://blog.livexia.site/2017/04/03/music_1/"/>
    <id>http://blog.livexia.site/2017/04/03/music_1/</id>
    <published>2017-04-03T09:15:08.000Z</published>
    <updated>2017-04-05T13:45:34.000Z</updated>
    
    <content type="html"><![CDATA[<hr>
<ul>
<li>演唱：Amy Chanrich</li>
<li>原唱：薛之谦</li>
<li>分类：翻唱</li>
<li>语种：华语</li>
<li>曲风：流行<a id="more"></a></li>
</ul>
<hr>
<iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="86" src="//music.163.com/outchain/player?type=2&id=437387277&auto=1&height=66"></iframe>

<h2 id="其实，我就在你方圆几里"><a href="#其实，我就在你方圆几里" class="headerlink" title="其实，我就在你方圆几里"></a>其实，我就在你方圆几里</h2><p>Amy Chanrich</p>
<p>介绍： 搬运自5sing</p>
<p>其实，方圆几里，你还要我怎样，刚刚好<br>四首串烧</p>
<p>不需要借口<br>爱淡了就放手<br>我不想听<br>你也没说平静的交错</p>
<p>随便找个理由<br>决定了就别回头<br>不爱你的人<br>说什么都没用</p>
<p>分开时难过不能说<br>谁没谁不能好好过<br>那天我们走了很久没有争吵过</p>
<p>分开时难过不要说<br>如果被你一笑而过<br>还不如让你选择想要的生活</p>
<p>与其在你不要的世界里<br>不如痛快把你忘记<br>这道理谁都懂 说容易 爱透了还要嘴硬<br>我宁愿 留在你方圆几里<br>我的心 要不回就送你<br>因为我爱你 和你没关系</p>
<p>与其在你不要的世界里<br>不如痛快把你忘记<br>我都会轻描淡写仿佛没爱过<br>其实我根本没人说<br>其实我没你不能活<br>可惜我 谁劝都不听</p>
<p>分开后我会笑着说<br>当朋友问你关于我<br>我都会轻描淡写仿佛没爱过<br>其实我根本没人说<br>陪你走的路你不能忘<br>因为那是我 最快乐的时光</p>
<p>你别太在意我身上的记号</p>
<hr>
<h2 id="链接"><a href="#链接" class="headerlink" title="链接"></a>链接</h2><p><a href="http://5sing.kugou.com/fc/15329562.html" target="_blank" rel="external">5Sing</a></p>
<p><a href="http://music.163.com/#/program?id=791256820" target="_blank" rel="external">网易云</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;演唱：Amy Chanrich&lt;/li&gt;
&lt;li&gt;原唱：薛之谦&lt;/li&gt;
&lt;li&gt;分类：翻唱&lt;/li&gt;
&lt;li&gt;语种：华语&lt;/li&gt;
&lt;li&gt;曲风：流行
    
    </summary>
    
      <category term="Music" scheme="http://blog.livexia.site/categories/Music/"/>
    
    
      <category term="music" scheme="http://blog.livexia.site/tags/music/"/>
    
  </entry>
  
  <entry>
    <title>The third week|第三周</title>
    <link href="http://blog.livexia.site/2017/04/03/post_4/"/>
    <id>http://blog.livexia.site/2017/04/03/post_4/</id>
    <published>2017-04-03T03:01:06.000Z</published>
    <updated>2017-04-05T12:43:20.000Z</updated>
    
    <content type="html"><![CDATA[<p> 接上周：</p>
<p>TODO：<del>完善爬虫，完整解决输出格式问题，加入随机ua模块。</del></p>
<p>代码：<a href="https://github.com/livexia/douban_top250" target="_blank" rel="external">livexia/douban_top250</a><br><a id="more"></a><br>解决输出问题，整理输出格式，深入理解了items，pipeline。输出无错误。截图见github。</p>
<p>增加了随机UA模块，中间件为useragent.py,文件结构如下</p>
<pre><code>├── douban_top250
│   └── spiders
│       ├── __init__.py
│       ├── top250.py
│       └── useragent.py
│    …...
</code></pre><p>运行结果见github。</p>
<p>下周</p>
<p>TODO:加入其他反爬虫功能，尝试编写针对网易云的爬虫</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt; 接上周：&lt;/p&gt;
&lt;p&gt;TODO：&lt;del&gt;完善爬虫，完整解决输出格式问题，加入随机ua模块。&lt;/del&gt;&lt;/p&gt;
&lt;p&gt;代码：&lt;a href=&quot;https://github.com/livexia/douban_top250&quot;&gt;livexia/douban_top250&lt;/a&gt;&lt;br&gt;
    
    </summary>
    
      <category term="创新实践" scheme="http://blog.livexia.site/categories/%E5%88%9B%E6%96%B0%E5%AE%9E%E8%B7%B5/"/>
    
    
      <category term="python" scheme="http://blog.livexia.site/tags/python/"/>
    
      <category term="scrapy" scheme="http://blog.livexia.site/tags/scrapy/"/>
    
  </entry>
  
  <entry>
    <title>The second week|第二周</title>
    <link href="http://blog.livexia.site/2017/04/03/post_3/"/>
    <id>http://blog.livexia.site/2017/04/03/post_3/</id>
    <published>2017-04-03T02:38:44.000Z</published>
    <updated>2017-04-05T12:43:15.000Z</updated>
    
    <content type="html"><![CDATA[<p> 由于中文教程版本以及目标网站的下线，我改学英文最新的教程。</p>
<p>目标链接为：<a href="http://quotes.toscrape.com/" target="_blank" rel="external">toscrape</a><br><a id="more"></a><br>完成网站练习之后，我开始尝试爬取豆瓣电影top250，由于豆瓣使用了检测UA信息的反爬虫技术，但是我没有添加ua信息，导致爬虫返回403，没有取得任何结果。</p>
<p>在settings.py中加入ua，问题解决。</p>
<pre><code>scrapy crawl top250 -o top250.json
</code></pre><p>启动spider，将结果储存在top250.json文件中，由于编码问题，json无法直接阅读。</p>
<pre><code>scrapy crawl top250 -o top250.csv
</code></pre><p>启动spider，将结果储存在top250.csv文件中</p>
<p>利用Pipeline 处理爬取得到的数据，固定格式。</p>
<p>转化编码失败，通过pipeline错误。</p>
<p>TODO：完善爬虫，完整解决输出格式问题，加入随机ua模块。</p>
<p>代码：<a href="https://github.com/livexia/douban_top250" target="_blank" rel="external">livexia/douban_top250</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt; 由于中文教程版本以及目标网站的下线，我改学英文最新的教程。&lt;/p&gt;
&lt;p&gt;目标链接为：&lt;a href=&quot;http://quotes.toscrape.com/&quot;&gt;toscrape&lt;/a&gt;&lt;br&gt;
    
    </summary>
    
      <category term="创新实践" scheme="http://blog.livexia.site/categories/%E5%88%9B%E6%96%B0%E5%AE%9E%E8%B7%B5/"/>
    
    
      <category term="python" scheme="http://blog.livexia.site/tags/python/"/>
    
      <category term="scrapy" scheme="http://blog.livexia.site/tags/scrapy/"/>
    
  </entry>
  
  <entry>
    <title>The first week|第一周</title>
    <link href="http://blog.livexia.site/2017/04/03/post_2/"/>
    <id>http://blog.livexia.site/2017/04/03/post_2/</id>
    <published>2017-04-03T02:14:58.000Z</published>
    <updated>2017-04-05T12:43:10.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="入门学习scrapy"><a href="#入门学习scrapy" class="headerlink" title="入门学习scrapy"></a>入门学习scrapy</h2><p>系统：osx<br><a id="more"></a></p>
<blockquote>
<p>按照<a href="http://scrapy-chs.readthedocs.io/zh_CN/1.0/intro/tutorial.html" target="_blank" rel="external">scrapy-chs.readthedocs.io</a></p>
<p>目标网站 <a href="http://www.dmoz.org/" target="_blank" rel="external">Open Directory Project</a></p>
</blockquote>
<p>安装Scrapy</p>
<p>Anaconda：</p>
<pre><code>conda install -c scrapinghub scrapy
</code></pre><p>创建项目tutorial</p>
<pre><code>$ scrapy startproject tutorial
</code></pre><p>项目结构</p>
<pre><code>$ tree tutorial
tutorial
├── scrapy.cfg
└── tutorial
   ├── __init__.py
   ├── __pycache__
   ├── items.py
   ├── middlewares.py
   ├── pipelines.py
   ├── settings.py
   └── spiders
       ├── __init__.py
       └── __pycache__
</code></pre><p>定义item</p>
<p>用来存放名字、url、网站的描述</p>
<pre><code>vim ./totorial/totorial/items.py
import scrapy

class DmozItem(scrapy.Item):
   title = scrapy.Field()
   link = scrapy.Field()
   desc = scrapy.Field()
   pass
</code></pre><p>写一个spider</p>
<pre><code>$ vim ./tutorial/tutorial/spiders/dmoz_spider.py

import scrapy

class DmozSpider(scrapy.Spider):
   name = &quot;dmoz&quot;
   allowed_domains = [&quot;dmoz.org&quot;]
   start_urls = [
       &quot;http://www.dmoz.org/Computers/Programming/Languages/Python/Books/&quot;,
       &quot;http://www.dmoz.org/Computers/Programming/Languages/Python/Resources/&quot;
   ]

   def parse(self, response):
       filename = response.url.split(&quot;/&quot;)[-2] + &apos;.html&apos;
       with open(filename, &apos;wb&apos;) as f:
           f.write(response.body)

#name : 该spider的名字，唯一

#start_urls : 该spider的起始地址，后续的地址由起始地址爬取得到

#parse() 是spider的一个方法。 被调用时，每个初始URL完成下载后生成的 Response 对象将会作为唯一的参数传递给该函数。 该方法负责解析返回的数据(response data)，提取数据(生成item)以及生成需要进一步处理的URL的 Request 对象。
</code></pre><p>启动spider：<br>根目录下</p>
<pre><code>$ scrapy crawl dmoz
2017-03-16 14:55:22 [scrapy.utils.log] INFO: Scrapy 1.3.3 started (bot: tutorial)
2017-03-16 14:55:22 [scrapy.utils.log] INFO: Overridden settings: {&apos;BOT_NAME&apos;: &apos;tutorial&apos;, &apos;NEWSPIDER_MODULE&apos;: &apos;tutorial.spiders&apos;, &apos;ROBOTSTXT_OBEY&apos;: True, &apos;SPIDER_MODULES&apos;: [&apos;tutorial.spiders&apos;]}
2017-03-16 14:55:22 [scrapy.middleware] INFO: Enabled extensions:
[&apos;scrapy.extensions.corestats.CoreStats&apos;,
&apos;scrapy.extensions.telnet.TelnetConsole&apos;,
&apos;scrapy.extensions.logstats.LogStats&apos;]
2017-03-16 14:55:23 [scrapy.middleware] INFO: Enabled downloader middlewares:
[&apos;scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware&apos;,
&apos;scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware&apos;,
&apos;scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware&apos;,
&apos;scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware&apos;,
&apos;scrapy.downloadermiddlewares.useragent.UserAgentMiddleware&apos;,
&apos;scrapy.downloadermiddlewares.retry.RetryMiddleware&apos;,
&apos;scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware&apos;,
&apos;scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware&apos;,
&apos;scrapy.downloadermiddlewares.redirect.RedirectMiddleware&apos;,
&apos;scrapy.downloadermiddlewares.cookies.CookiesMiddleware&apos;,
&apos;scrapy.downloadermiddlewares.stats.DownloaderStats&apos;]
2017-03-16 14:55:23 [scrapy.middleware] INFO: Enabled spider middlewares:
[&apos;scrapy.spidermiddlewares.httperror.HttpErrorMiddleware&apos;,
&apos;scrapy.spidermiddlewares.offsite.OffsiteMiddleware&apos;,
&apos;scrapy.spidermiddlewares.referer.RefererMiddleware&apos;,
&apos;scrapy.spidermiddlewares.urllength.UrlLengthMiddleware&apos;,
&apos;scrapy.spidermiddlewares.depth.DepthMiddleware&apos;]
2017-03-16 14:55:23 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2017-03-16 14:55:23 [scrapy.core.engine] INFO: Spider opened
2017-03-16 14:55:23 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-16 14:55:23 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2017-03-16 14:55:25 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET http://www.dmoz.org/robots.txt&gt; (referer: None)
2017-03-16 14:55:26 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET http://www.dmoz.org/Computers/Programming/Languages/Python/Resources/&gt; (referer: None)
2017-03-16 14:55:26 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET http://www.dmoz.org/Computers/Programming/Languages/Python/Books/&gt; (referer: None)
2017-03-16 14:55:26 [scrapy.core.engine] INFO: Closing spider (finished)
2017-03-16 14:55:26 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{&apos;downloader/request_bytes&apos;: 734,
&apos;downloader/request_count&apos;: 3,
&apos;downloader/request_method_count/GET&apos;: 3,
&apos;downloader/response_bytes&apos;: 16015,
&apos;downloader/response_count&apos;: 3,
&apos;downloader/response_status_count/200&apos;: 3,
&apos;finish_reason&apos;: &apos;finished&apos;,
&apos;finish_time&apos;: datetime.datetime(2017, 3, 16, 6, 55, 26, 472574),
&apos;log_count/DEBUG&apos;: 4,
&apos;log_count/INFO&apos;: 7,
&apos;response_received_count&apos;: 3,
&apos;scheduler/dequeued&apos;: 2,
&apos;scheduler/dequeued/memory&apos;: 2,
&apos;scheduler/enqueued&apos;: 2,
&apos;scheduler/enqueued/memory&apos;: 2,
&apos;start_time&apos;: datetime.datetime(2017, 3, 16, 6, 55, 23, 30734)}
2017-03-16 14:55:26 [scrapy.core.engine] INFO: Spider closed (finished)
</code></pre><p>目录结构</p>
<pre><code>$ tree tutorial
tutorial
├── Books.html
├── Resources.html
├── scrapy.cfg
└── tutorial
   ├── __init__.py
   ├── __pycache__
   │   ├── __init__.cpython-36.pyc
   │   └── settings.cpython-36.pyc
   ├── items.py
   ├── middlewares.py
   ├── pipelines.py
   ├── settings.py
   └── spiders
       ├── __init__.py
       ├── __pycache__
       │   ├── __init__.cpython-36.pyc
       │   └── dmoz_spider.cpython-36.pyc
       └── dmoz_spider.py
</code></pre><p>提取数据<br>XPath</p>
<p>周总结：周一、二学习了部分正则（没有做笔记），之后看了部分的urllib，在之后就是开始学习scrapy，目前才处于开始学习的阶段。<br>因为期间电脑磁盘出了问题，学习时间有所下降。</p>
<p>下周目标：入门学习scrapy，完整实现爬取dmoz，尝试利用scrapy对豆瓣电影top 250进行爬取。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;入门学习scrapy&quot;&gt;&lt;a href=&quot;#入门学习scrapy&quot; class=&quot;headerlink&quot; title=&quot;入门学习scrapy&quot;&gt;&lt;/a&gt;入门学习scrapy&lt;/h2&gt;&lt;p&gt;系统：osx&lt;br&gt;
    
    </summary>
    
      <category term="创新实践" scheme="http://blog.livexia.site/categories/%E5%88%9B%E6%96%B0%E5%AE%9E%E8%B7%B5/"/>
    
    
      <category term="python" scheme="http://blog.livexia.site/tags/python/"/>
    
      <category term="scrapy" scheme="http://blog.livexia.site/tags/scrapy/"/>
    
  </entry>
  
  <entry>
    <title>Innovation practice|创新实践 方向选择</title>
    <link href="http://blog.livexia.site/2017/04/03/post_1/"/>
    <id>http://blog.livexia.site/2017/04/03/post_1/</id>
    <published>2017-04-03T01:59:51.000Z</published>
    <updated>2017-04-05T12:43:05.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="方向：利用Python抓取互联网信息"><a href="#方向：利用Python抓取互联网信息" class="headerlink" title="方向：利用Python抓取互联网信息"></a><em>方向：利用Python抓取互联网信息</em></h1><h2 id="学习目标"><a href="#学习目标" class="headerlink" title="学习目标"></a>学习目标</h2><ul>
<li>网页知识，浏览器抓包、拦截<a id="more"></a></li>
<li><p>异常处理，浏览器代码分析</p>
</li>
<li><p>多线程，多进程编程</p>
</li>
<li><p>爬虫模块：urllib,requests….</p>
</li>
<li><p>正则表达式</p>
</li>
<li><p>爬虫框架Scrapy</p>
</li>
<li>代理池，模拟UA…..</li>
</ul>
<h2 id="主要目标"><a href="#主要目标" class="headerlink" title="主要目标"></a>主要目标</h2><ul>
<li><p>模拟登录网易云音乐，获取个人歌单，并抓取歌曲热门评论。</p>
</li>
<li><p>抓取游戏销售平台steam上所有游戏的价格及优惠信息。(酌情)</p>
</li>
<li><p>抓取当周销量销售前100游戏的热门评价(酌情)</p>
</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;方向：利用Python抓取互联网信息&quot;&gt;&lt;a href=&quot;#方向：利用Python抓取互联网信息&quot; class=&quot;headerlink&quot; title=&quot;方向：利用Python抓取互联网信息&quot;&gt;&lt;/a&gt;&lt;em&gt;方向：利用Python抓取互联网信息&lt;/em&gt;&lt;/h1&gt;&lt;h2 id=&quot;学习目标&quot;&gt;&lt;a href=&quot;#学习目标&quot; class=&quot;headerlink&quot; title=&quot;学习目标&quot;&gt;&lt;/a&gt;学习目标&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;网页知识，浏览器抓包、拦截
    
    </summary>
    
      <category term="创新实践" scheme="http://blog.livexia.site/categories/%E5%88%9B%E6%96%B0%E5%AE%9E%E8%B7%B5/"/>
    
    
      <category term="python" scheme="http://blog.livexia.site/tags/python/"/>
    
  </entry>
  
</feed>
